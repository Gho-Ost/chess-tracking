{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ipywidgets import Video\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture('Chess_Data\\\\chess_easy1.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_closest_points_to_corners(points, corners):\n",
    "    closest_points = []\n",
    "    for corner in corners:\n",
    "        distances = np.linalg.norm(points - corner, axis=1)\n",
    "        closest_point_index = np.argmin(distances)\n",
    "        closest_points.append(points[closest_point_index])\n",
    "    return np.array(closest_points)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    frame_with_boxes = frame.copy()\n",
    "    dst = cv2.cornerHarris(blurred, 5, 3, 0.02)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    corners = np.argwhere(dst > 0.01 * dst.max())\n",
    "\n",
    "    # Find corners closest to image corners\n",
    "    image_corners = np.array([[0, 0], [0, frame.shape[1]], [frame.shape[0], 0], [frame.shape[0], frame.shape[1]]])\n",
    "    closest_corners = find_closest_points_to_corners(corners, image_corners)\n",
    "\n",
    "    # Draw the resulting trapezoid\n",
    "    #cv2.polylines(frame_with_boxes, [closest_corners], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    #frame_with_boxes[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "\n",
    "    trapezoid_pts = np.array([[closest_corners[0][1], closest_corners[0][0]], [closest_corners[2][1], closest_corners[2][0]], [closest_corners[3][1], closest_corners[3][0]], [closest_corners[1][1], closest_corners[1][0]]], np.int32)\n",
    "    trapezoid_pts = trapezoid_pts.reshape((-1, 1, 2))\n",
    "    cv2.polylines(frame_with_boxes, [trapezoid_pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "\n",
    "    for corner in closest_corners:\n",
    "        cv2.circle(frame_with_boxes, tuple(corner[::-1]), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Frame with Trapezoid', frame_with_boxes)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:   \n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    frame_with_boxes = frame.copy()\n",
    "    total_area = frame.shape[0] * frame.shape[1]\n",
    "    giant_contour = np.vstack(contours)\n",
    "\n",
    "    # Calculate the bounding box of the giant contour\n",
    "    x, y, w, h = cv2.boundingRect(giant_contour)\n",
    "    dst = cv2.cornerHarris(gray, 3, 3, 0.04)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    corners = np.argwhere(dst > 0.01 * dst.max())\n",
    "\n",
    "    lc = np.min(corners[:, 0])\n",
    "    tc = np.min(corners[:, 1])\n",
    "    rc = np.max(corners[:, 0])\n",
    "    bc = np.max(corners[:, 1])\n",
    "    frame_with_boxes[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "\n",
    "    # Draw the resulting bounding box\n",
    "    cv2.rectangle(frame_with_boxes, (tc, lc), (bc, rc), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Frame with Giant Bounding Box', frame_with_boxes)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:   \n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    frame_with_boxes = frame.copy()\n",
    "    total_area = frame.shape[0] * frame.shape[1]\n",
    "    giant_contour = np.vstack(contours)\n",
    "\n",
    "    # Calculate the bounding box of the giant contour\n",
    "    x, y, w, h = cv2.boundingRect(giant_contour)\n",
    "    dst = cv2.cornerHarris(gray, 3, 3, 0.04)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    corners = np.argwhere(dst > 0.01 * dst.max())\n",
    "\n",
    "    lc = np.min(corners[:, 0])\n",
    "    tc = np.min(corners[:, 1])\n",
    "    rc = np.max(corners[:, 0])\n",
    "    bc = np.max(corners[:, 1])\n",
    "    frame_with_boxes[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "\n",
    "    # Draw the resulting bounding box\n",
    "    cv2.rectangle(frame_with_boxes, (tc, lc), (bc, rc), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Frame with Giant Bounding Box', frame_with_boxes)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    frame_with_boxes = frame.copy()\n",
    "    total_area = frame.shape[0] * frame.shape[1]\n",
    "    threshold_lower = 0\n",
    "    threshold_upper = np.inf\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > threshold_lower and area<threshold_upper:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame_with_boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Display the result\n",
    "    dst = cv2.cornerHarris(gray, 3, 3, 0.04)\n",
    "    # result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst, None)\n",
    "\n",
    "    # Threshold for an optimal value, it may vary depending on the image.\n",
    "    frame[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "    cv2.imshow('Frame with Boxes', frame_with_boxes)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Use Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Use HoughLinesP to detect lines in the edges\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=10)\n",
    "\n",
    "    # Draw the detected lines on the original frame\n",
    "    frame_with_lines = frame.copy()\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame_with_lines, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with detected lines\n",
    "    cv2.imshow('Frame with Lines', frame_with_lines)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keypoint Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "\n",
    "while True:   \n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    sift_kp1, sift_desc1 = sift.detectAndCompute(gray, None)\n",
    "    img_kp1 = cv2.drawKeypoints(\n",
    "        frame, sift_kp1, None, flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT\n",
    "    )\n",
    "\n",
    "    cv2.imshow('Video Frame', img_kp1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:   \n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    dst = cv2.cornerHarris(gray, 3, 3, 0.04)\n",
    "    # result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst, None)\n",
    "\n",
    "    # Threshold for an optimal value, it may vary depending on the image.\n",
    "    frame[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "\n",
    "    cv2.imshow('Video Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chess_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
